{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7955f19",
   "metadata": {},
   "source": [
    "# SESSION 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fa0d333",
   "metadata": {},
   "source": [
    "TOC\n",
    "1. Convolutional Neural Networks (CNNs)<br>\n",
    "2. Transfer learning<br>\n",
    "3. Data Augmentation<br>\n",
    "4. Image preprocessing<br>\n",
    "5. Loss Functions<br>\n",
    "6. Optimization Algorithms<br>\n",
    "7. Performance metrics<br> \n",
    "\t7.1 Accuracy<br>\n",
    "\t7.2 Precision, Recall, and F1 Score<br>\n",
    "\t7.3 Confusion Matrix<br>\n",
    "\t7.4 ROC Curve<br>\n",
    "8. API Integration with TensorFlow Serving"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88836804",
   "metadata": {},
   "source": [
    "## 1. Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50faccf0",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are a class of neural networks commonly used in computer vision tasks, which use convolutional layers to learn spatial features in images and other visual data.\n",
    "\n",
    "Here's an example of how to implement a simple CNN in Python using the Keras library:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f838fbee",
   "metadata": {},
   "source": [
    "```In this example, we define a CNN model with two convolutional layers, two max pooling layers, a flatten layer, and two dense layers. We then compile the model with an Adam optimizer and categorical cross-entropy loss function. Next, we load and preprocess the MNIST dataset, and finally we train the model on the dataset for 10 epochs using a batch size of 128. By the end of training, we should have a CNN model that can classify handwritten digits with high accuracy.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a55490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 33s 69ms/step - loss: 0.2133 - accuracy: 0.9356 - val_loss: 0.0679 - val_accuracy: 0.9801\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 33s 71ms/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.0356 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0314 - val_accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0295 - val_accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0382 - val_accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0356 - val_accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0323 - val_accuracy: 0.9899\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0330 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1832b7dde50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess the data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02416bdd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a615e53a",
   "metadata": {},
   "source": [
    "## 2. Transfer learning<br>\n",
    "Transfer learning is a technique in deep learning where pre-trained models are used as a starting point for new models, instead of training a model from scratch. In transfer learning, we typically take a pre-trained model that was trained on a large dataset, and then we remove the last few layers of the model and replace them with new layers that are specific to our task. \n",
    "\n",
    "Here's an example of how to implement transfer learning using the Keras library:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4407d751",
   "metadata": {},
   "source": [
    "```In this example, we load the pre-trained VGG16 model that was trained on the ImageNet dataset. We then freeze the pre-trained layers so that they will not be updated during training. Next, we add new layers specific to our task, which in this case is a binary classification task. We create the new model by specifying the input and output layers, and then we compile the model with an RMSprop optimizer and categorical cross-entropy loss function. Finally, we load and preprocess the training data using an ImageDataGenerator, and then we train the model using the fit_generator method. By the end of training, we should have a model that is able to classify new images with high accuracy, despite being trained on a much smaller dataset than the original pre-trained model.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b884cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers for our task\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_generator, steps_per_epoch=100, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0909ae23",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e57f007b",
   "metadata": {},
   "source": [
    "## 3. Data augmentation\n",
    "Data augmentation is a technique used in machine learning to artificially increase the size of a dataset by creating new training examples from existing ones. This is done by applying random transformations to the existing examples, such as flipping, rotating, scaling, cropping, and adding noise. Data augmentation is especially useful in image recognition tasks, where we can generate new images by applying these transformations to existing ones.\n",
    "\n",
    "Here's an example of how to implement data augmentation using the Keras library:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "036a8532",
   "metadata": {},
   "source": [
    "```In this example, we use the Keras ImageDataGenerator to apply various transformations to the training data, such as rotation, shifting, shearing, zooming, flipping, and filling. We specify the range of each transformation using parameters like rotation_range, width_shift_range, and horizontal_flip. We then load and preprocess the training data using the ImageDataGenerator, and use the resulting generator to train the model using the fit_generator method. By using data augmentation, we can generate many new training examples from a small dataset, which can improve the performance of the model and reduce overfitting.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Train the model with augmented data\n",
    "model.fit_generator(train_generator, steps_per_epoch=100, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cbe798f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "198d05ff",
   "metadata": {},
   "source": [
    "## 4. Image preprocessing\n",
    "Image preprocessing is a crucial step in any computer vision task, where we prepare the image data to be fed into a machine learning model. This involves tasks such as resizing, normalizing, and centering the images, as well as removing any unwanted noise or artifacts.\n",
    "\n",
    "Here's an example of how to preprocess images using the OpenCV library:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1410d28",
   "metadata": {},
   "source": [
    "```In this example, we use the OpenCV library to preprocess an image. We first load the image using the imread function, and then resize it to a fixed size using the resize function. We then convert the image to grayscale using the cvtColor function, and normalize it using the normalize function to scale the pixel values between 0 and 255. We then center the image by subtracting the mean pixel value of 127.5, and reshape it to a format that can be fed into a machine learning model. This preprocessing pipeline can be customized to suit the specific needs of the task at hand.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3255fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('Images/image.jpg')\n",
    "\n",
    "# Resize the image\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Normalize the image\n",
    "normalized = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Center the image\n",
    "centered = normalized - 127.5\n",
    "\n",
    "# Reshape the image\n",
    "reshaped = centered.reshape((1, 224, 224, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f05f8cec",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f1135f8",
   "metadata": {},
   "source": [
    "## 5. Loss Functions\n",
    "\n",
    "In machine learning, a loss function is used to measure the difference between the predicted output of a model and the actual output. The goal of training a model is to minimize this loss function, which in turn improves the accuracy of the model. There are various types of loss functions, such as mean squared error, cross-entropy, and hinge loss, among others.\n",
    "\n",
    "Here's an example of how to define and use a mean squared error loss function in Python:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea58c462",
   "metadata": {},
   "source": [
    "```In this example, we define a mean squared error loss function using TensorFlow. The function takes in two arguments, y_true and y_pred, which represent the true and predicted outputs, respectively. The function then computes the mean squared error between these two inputs using the reduce_mean and square functions provided by TensorFlow.\n",
    "\n",
    "We then use this loss function to calculate the mean squared error between two example tensors y_true and y_pred. The result of the loss function is then printed to the console, which gives us an idea of how well our model is performing.\n",
    "\n",
    "This is just one example of a loss function, and there are many other types of loss functions that can be used depending on the specific problem being solved.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e410260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  tf.Tensor(0.25, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the mean squared error loss function\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Example usage of the loss function\n",
    "y_true = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
    "y_pred = tf.constant([[1.5, 2.5, 3.5], [3.5, 4.5, 5.5], [6.5, 7.5, 8.5]], dtype=tf.float32)\n",
    "\n",
    "mse = mse_loss(y_true, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e39cbfd4",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47db4797",
   "metadata": {},
   "source": [
    "## 6. Optimization Algorithms\n",
    "\n",
    "Optimization algorithms are used to update the weights and biases of a machine learning model during the training process. The goal of these algorithms is to minimize the loss function of the model and improve its accuracy. There are several types of optimization algorithms, such as stochastic gradient descent, Adam, and Adagrad, among others.\n",
    "\n",
    "Here's an example of how to use the stochastic gradient descent optimization algorithm in Python:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4110ed59",
   "metadata": {},
   "source": [
    "```In this example, we define a neural network model with two dense layers using TensorFlow's Keras API. We also define a sparse categorical cross-entropy loss function, which is commonly used for multi-class classification problems.\n",
    "\n",
    "We then define the stochastic gradient descent optimizer with a learning rate of 0.1. We load the MNIST dataset and prepare it for training by normalizing the pixel values and creating a TensorFlow dataset object.\n",
    "\n",
    "We then train the model for five epochs using the stochastic gradient descent optimizer. For each batch of training data, we compute the loss using the defined loss function and calculate the gradients using TensorFlow's GradientTape. We then update the weights and biases of the model using the optimizer's apply_gradients method.\n",
    "\n",
    "Finally, we print the loss value every 100 steps to monitor the progress of the training process.```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "334bd4b3",
   "metadata": {},
   "source": [
    "This is just one example of an optimization algorithm, and there are many other types of optimization algorithms that can be used depending on the specific problem being solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b204ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model and loss function\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation='relu', input_shape=(784,)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Define the stochastic gradient descent optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# Load the MNIST dataset and prepare it for training\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(10000).batch(32)\n",
    "\n",
    "# Train the model using stochastic gradient descent\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits = model(x_batch_train, training=True)\n",
    "      loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    if step % 100 == 0:\n",
    "      print(\"Epoch: {}, Step: {}, Loss: {}\".format(epoch, step, loss_value))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "829d8457",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bcb5d86",
   "metadata": {},
   "source": [
    "##  7. Performance metrics \n",
    "\n",
    "Performance metrics are used to evaluate the performance of machine learning models. They help us to understand how well our model is performing and whether it needs any improvements. In this section, we will discuss some of the common performance metrics used in machine learning and how to implement them in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "213dd382",
   "metadata": {},
   "source": [
    "### 7.1 Accuracy\n",
    "Accuracy is the most commonly used performance metric for classification problems. It is defined as the number of correct predictions divided by the total number of predictions. The code to calculate accuracy using scikit-learn is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7589d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d29e054c",
   "metadata": {},
   "source": [
    "### 7.2 Precision, Recall, and F1 Score\n",
    "Precision, recall, and F1 score are commonly used performance metrics for binary classification problems. Precision is the number of true positives divided by the number of true positives plus false positives. Recall is the number of true positives divided by the number of true positives plus false negatives. F1 score is the harmonic mean of precision and recall. The code to calculate precision, recall, and F1 score using scikit-learn is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05608c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6666666666666666\n",
      "Recall:  1.0\n",
      "F1 score:  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1]\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2091035d",
   "metadata": {},
   "source": [
    "### 7.3 Confusion Matrix\n",
    "A confusion matrix is a table that summarizes the performance of a machine learning model for each class. The table compares the actual class with the predicted class. The code to calculate the confusion matrix using scikit-learn is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d77ff26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[1 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion matrix: \")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aa087e0",
   "metadata": {},
   "source": [
    "### 7.4 ROC Curve\n",
    "The Receiver Operating Characteristic (ROC) curve is a plot that shows the trade-off between the true positive rate and false positive rate for different thresholds of the predicted probabilities. The code to plot the ROC curve using scikit-learn is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a629c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred_prob = [0.2, 0.8, 0.4, 0.6]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c74dc11",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a920f57f",
   "metadata": {},
   "source": [
    "## 8. API Integration with TensorFlow Serving\n",
    "\n",
    "To integrate a TensorFlow model with an API using TensorFlow Serving, we need to follow a few steps:\n",
    "\n",
    "Export the TensorFlow model in the SavedModel format\n",
    "Install and start the TensorFlow Serving server\n",
    "Send prediction requests to the server using a RESTful API\n",
    "Here is the Python code to perform these steps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c3661ef",
   "metadata": {},
   "source": [
    "```In this code, we first load a pre-trained ResNet50 model and save it in the SavedModel format using the tf.saved_model.save function. Next, we start the TensorFlow Serving server using Docker and bind the saved model to the server. Finally, we load an example image, preprocess it, and send a prediction request to the server using the RESTful API. The server returns a JSON object containing the predicted probabilities for each class, which we can then use for further processing.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Step 1: Export the TensorFlow model in the SavedModel format\n",
    "model = ResNet50(weights='imagenet')\n",
    "tf.saved_model.save(model, 'resnet_saved_model')\n",
    "\n",
    "# Step 2: Install and start the TensorFlow Serving server\n",
    "# You can install the TensorFlow Serving server using Docker or by building from source.\n",
    "# Here is an example command to start the server:\n",
    "# docker run -p 8501:8501 --mount type=bind,source=/path/to/resnet_saved_model,target=/models/resnet -e MODEL_NAME=resnet -t tensorflow/serving\n",
    "\n",
    "# Step 3: Send prediction requests to the server using a RESTful API\n",
    "image_path = 'Images/image.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image, channels=3)\n",
    "image = tf.image.resize(image, [224, 224])\n",
    "image = tf.cast(image, tf.float32) / 255.0\n",
    "image = tf.expand_dims(image, 0)\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": image.numpy().tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "response = requests.post('http://localhost:8501/v1/models/resnet:predict', data=data, headers=headers)\n",
    "prediction = json.loads(response.text)['predictions'][0]\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11058d32",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1a104daade7a70772ad630bf0568980f4e260449ff540bcd2b6baf0ecd3487d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
