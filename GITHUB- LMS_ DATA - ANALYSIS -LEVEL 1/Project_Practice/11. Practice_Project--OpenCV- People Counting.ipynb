{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d5942e",
   "metadata": {},
   "source": [
    "## Practice Project - OpenCV based : People Counting\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21dcd122",
   "metadata": {},
   "source": [
    "### Table of Contents<br>\n",
    "    Problem statement\n",
    "    1. Fancy Indexing\n",
    "    2. Importing Libraries\n",
    "    3. Python implementation\n",
    "    4. Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43021a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture device\n",
    "cap = cv2.VideoCapture('data/people-capture.mp4')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "# Load the trained Haar cascade classifier for detecting people\n",
    "person_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
    "\n",
    "# Initialize variables for counting people\n",
    "count = 0\n",
    "is_counting = False\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture device\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect people in the grayscale frame\n",
    "    people = person_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    # Draw rectangles around the detected people\n",
    "    for (x,y,w,h) in people:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    # Check if people are entering\n",
    "    if len(people) > 0 and not is_counting:\n",
    "        count += 1\n",
    "        is_counting = True\n",
    "    elif len(people) == 0 and is_counting:\n",
    "        is_counting = False\n",
    "    \n",
    "    # Display the frame with the detected people and the count\n",
    "    cv2.putText(frame, \"Count: {}\".format(count), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # Write the frame to the output video file\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Wait for key press and check for 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything and close the windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture device\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"data/people-capture.mp4\")\n",
    "xvalues = list()\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('data/output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "# Load the trained Haar cascade classifier for detecting people\n",
    "person_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
    "\n",
    "# Initialize variables for counting people\n",
    "count = 0\n",
    "is_counting = False\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture device\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect people in the grayscale frame\n",
    "    people = person_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    # Draw rectangles around the detected people\n",
    "    for (x,y,w,h) in people:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    # Check if people are entering\n",
    "    if len(people) > 0 and not is_counting:\n",
    "        count += 1\n",
    "        is_counting = True\n",
    "    elif len(people) == 0 and is_counting:\n",
    "        is_counting = False\n",
    "    \n",
    "    # Display the frame with the detected people and the count\n",
    "    cv2.putText(frame, \"Count: {}\".format(count), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # Write the frame to the output video file\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Wait for key press and check for 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything and close the windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1790b20b",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "``` Fancy indexing allows to select entire rows or columns out of order on a numpy array. ```<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c900fbd8",
   "metadata": {},
   "source": [
    "#### 1. Fancy Indexing\n",
    "Fancy indexing allows you to select entire rows or columns out of order,to show this, let's quickly build out a numpy array:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04b6aab4",
   "metadata": {},
   "source": [
    "#### 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bfea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f97930b",
   "metadata": {},
   "source": [
    "#### 3. Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up matrix\n",
    "arr2d = np.zeros((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b4daad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Length 10\n"
     ]
    }
   ],
   "source": [
    "#Length of array\n",
    "arr_length = arr2d.shape[1]\n",
    "print(\"Array Length\", arr_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b60f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
       "       [6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "       [7., 7., 7., 7., 7., 7., 7., 7., 7., 7.],\n",
       "       [8., 8., 8., 8., 8., 8., 8., 8., 8., 8.],\n",
       "       [9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up array\n",
    "\n",
    "for i in range(arr_length):\n",
    "    arr2d[i] = i\n",
    "    \n",
    "arr2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d9b54b",
   "metadata": {},
   "source": [
    "Fancy indexing allows the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5363f6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "       [6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "       [8., 8., 8., 8., 8., 8., 8., 8., 8., 8.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[[2,4,6,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b77b60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [7., 7., 7., 7., 7., 7., 7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Allows in any order\n",
    "arr2d[[6,4,2,7]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f575ec08",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
