{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project : Student attendance using face recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Importing Libraries```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import face_recognition: This imports the face_recognition library, which provides face detection and recognition capabilities.\n",
    "\n",
    "* import cv2: This imports the OpenCV library, which is used for image and video processing tasks.\n",
    "\n",
    "* import numpy as np: This imports the NumPy library, which provides support for multi-dimensional arrays and mathematical operations on them.\n",
    "\n",
    "* import csv: This imports the CSV library, which allows reading and writing CSV files.\n",
    "\n",
    "* import os: This imports the os module, which provides functions for interacting with the operating system, such as file and directory operations.\n",
    "\n",
    "* from datetime import datetime: This imports the datetime class from the datetime module, which allows working with dates and times.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps - Installing face_recognition Library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Install the C++ Module in VS Code IDE as shown below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align = \"middle\" src = 'photos/steps1.png' width = '700' height = auto>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Follow the steps to complete the installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align = \"middle\" src = 'photos/steps2.png' width = '700' height = auto>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other option is to Download using the link below:\n",
    "```\n",
    "https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align = \"middle\" src = 'photos/step3.png' width = '700' height = auto>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align = \"middle\" src = 'photos/step4.png' width = '700' height = auto>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align = \"middle\" src = 'photos/step5.png' width = '700' height = auto>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Installation Modules\n",
    "\n",
    "Please follow the below sequence of Install:\n",
    "\n",
    "* pip install cmake\n",
    "* pip install wheel\n",
    "* pip install dlib --user\n",
    "* pip install protobuf\n",
    "* pip install face_recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image as im"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The line video_capture = cv2.VideoCapture(0) initializes the video_capture object, which represents the video capturing device. In this case, 0 as the argument specifies that the default camera should be used for capturing video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In summary, the code loads images of known faces and extracts their face features using the face_recognition library. These encoded features can later be used for face recognition tasks, such as comparing them with faces detected in a live video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images of known faces and encode their face features\n",
    "jobs_image = face_recognition.load_image_file(\"face_recognisation/photos/jobs.jpg\")\n",
    "jobs_encoding = face_recognition.face_encodings(jobs_image)[0]\n",
    "face_location = face_recognition.face_locations(jobs_image)\n",
    "\n",
    "ratan_tata_image = face_recognition.load_image_file(\"face_recognisation/photos/tata.jpg\")\n",
    "ratan_tata_encoding = face_recognition.face_encodings(ratan_tata_image)[0]\n",
    "\n",
    "kohli_image = face_recognition.load_image_file(\"face_recognisation/photos/kohli.jpg\")\n",
    "kohli_encoding = face_recognition.face_encodings(kohli_image)[0]\n",
    "\n",
    "tesla_image = face_recognition.load_image_file(\"face_recognisation/photos/tesla.jpg\")\n",
    "tesla_encoding = face_recognition.face_encodings(tesla_image)[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. known_face_encoding: This list contains the face encodings of known faces. The encodings are stored in the order of the corresponding names in the known_faces_names list. In this case, the jobs_encoding, ratan_tata_encoding, kohli_encoding, and tesla_encoding variables (which were defined in the previous code snippet) are used to populate this list. These encodings represent the facial features of Steve Jobs, Ratan Tata, Virat Kohli, and an image related to Tesla, respectively.\n",
    "\n",
    "b. known_faces_names: This list contains the names corresponding to the known face encodings. The names are provided as strings and are arranged in the same order as the face encodings in the known_face_encoding list. In this case, the names are \"jobs\", \"ratan tata\", \"kohli\", and \"tesla\". These names identify the individuals associated with the respective face encodings.\n",
    "\n",
    "By organizing the face encodings and names in these lists, you can easily associate a detected face's encoding with its corresponding name during the face recognition process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of known face encodings and corresponding names\n",
    "known_face_encoding = [\n",
    "    jobs_encoding,\n",
    "    ratan_tata_encoding,\n",
    "    kohli_encoding,\n",
    "    tesla_encoding\n",
    "]\n",
    "\n",
    "known_faces_names = [\n",
    "    \"jobs\",\n",
    "    \"ratan tata\",\n",
    "    \"kohli\",\n",
    "    \"tesla\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable students is a copy of a list called known_faces_names. It is assumed that known_faces_names contains the names of students whose faces are known.\n",
    "\n",
    "The variables face_locations, face_encodings, and face_names are empty lists, which will be populated later in the code.\n",
    "\n",
    "The variable s is set to True, but its purpose is not clear from the given code snippet.\n",
    "\n",
    "The datetime.now() function is used to get the current date and time, and the strftime() method formats it to only include the year, month, and day in the format \"YYYY-MM-DD\". This formatted date is stored in the variable current_date.\n",
    "\n",
    "A CSV file is then opened with the filename being the current date concatenated with \".csv\". The file is opened in write mode, and if the file does not exist, it will be created.\n",
    "\n",
    "A csv.writer object named lnwriter is created, which will be used to write data to the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = known_faces_names.copy()\n",
    " \n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "s=True\n",
    " \n",
    " \n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    " \n",
    " \n",
    " \n",
    "f = open(current_date+'.csv','w+',newline = '')\n",
    "lnwriter = csv.writer(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step involves detecting faces in the frame and encoding their features. The face_recognition library is used for this purpose. The face_locations variable stores the locations of the detected faces in the smaller frame, while the face_encodings variable contains the corresponding face encodings.\n",
    "\n",
    "Finally, the face_names list is initialized to store the names associated with the detected faces. This list will be populated later in the code, possibly by matching the face encodings with a known set of encodings. The loop continues indefinitely, processing each frame in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Detect faces in the frame and encode their features\n",
    "    face_location = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encoding = face_recognition.face_encodings(rgb_small_frame.astype('uint8'), face_location)\n",
    "    face_names = []\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each face encoding in the face_encodings list, the code compares it with the known_face_encoding list using the compare_faces function from the face_recognition library. The result is stored in the matches list, where each element corresponds to a match or non-match for a known face.\n",
    "\n",
    "The code then initializes an empty string variable name to store the recognized person's name. It also calculates the face distance between the detected face and each known face using the face_distance function. The index of the best match is obtained by finding the index of the smallest face distance using np.argmin.\n",
    "\n",
    "If there is a match (matches[best_match_index] is True), the recognized person's name is assigned from the known_faces_names list based on the index of the best match. Finally, the recognized name is appended to the face_names list.\n",
    "\n",
    "This process allows the code to compare the face encodings of the detected faces with a known set of face encodings and assign names to the recognized faces, populating the face_names list accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encoding, face_encoding)\n",
    "        name = \"\"\n",
    "        face_distance = face_recognition.face_distance(known_face_encoding, face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "\n",
    "        if matches[best_match_index]:\n",
    "            name = known_faces_names[best_match_index]\n",
    "\n",
    "        face_names.append(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After appending the recognized name to the face_names list, the code checks if the name exists in the known_faces_names list. This check ensures that only known faces are considered for further processing.\n",
    "\n",
    "If the name is found in the known_faces_names list, the code proceeds to draw text on the frame indicating the presence of the recognized person. It uses the putText function from OpenCV to add text to the frame.\n",
    "\n",
    "The parameters for the putText function are as follows:\n",
    "\n",
    "frame: The frame on which the text will be drawn.\n",
    "name+' Present': The text to be displayed, indicating the presence of the recognized person.\n",
    "bottomLeftCornerOfText: The coordinates of the bottom-left corner of the text box.\n",
    "font: The font type.\n",
    "fontScale: The scale of the font.\n",
    "fontColor: The color of the font, specified as a tuple of RGB values.\n",
    "thickness: The thickness of the font stroke.\n",
    "lineType: The type of line used to draw the font.\n",
    "The code then checks if the recognized name is present in the students list, and if so, it removes the name from the list and prints the updated students list. This step suggests that the recognized person is a student and their attendance is being recorded.\n",
    "\n",
    "Next, the code gets the current time using the now.strftime(\"%H-%M-%S\") function, which formats the time as \"hours-minutes-seconds\". It writes the name and current time to the CSV file using the lnwriter.writerow([name,current_time]) function, presumably for attendance tracking purposes.\n",
    "\n",
    "Finally, the code displays the frame with the added text using cv2.imshow(\"attendence system\",frame). It also checks for the \"q\" key press and if detected, breaks the loop to exit the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_names.append(name)\n",
    "if name in known_faces_names:\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,100)\n",
    "    fontScale              = 1.5\n",
    "    fontColor              = (255,0,0)\n",
    "    thickness              = 3\n",
    "    lineType               = 2\n",
    "\n",
    "    cv2.putText(frame,name+' Present', \n",
    "        bottomLeftCornerOfText, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        thickness,\n",
    "        lineType)\n",
    "\n",
    "    if name in students:\n",
    "        students.remove(name)\n",
    "        print(students)\n",
    "        current_time = now.strftime(\"%H-%M-%S\")\n",
    "        lnwriter.writerow([name,current_time])\n",
    "    cv2.imshow(\"attendence system\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video_capture.release(): This function releases the resources associated with the video capture. It is necessary to release the video capture when it is no longer needed to free up system resources.\n",
    "\n",
    "cv2.destroyAllWindows(): This function closes all windows created by OpenCV. It is useful to ensure that all windows are closed properly before the program exits.\n",
    "\n",
    "f.close(): This function closes the file object f that was used to write data to a file, presumably the CSV file for attendance records. It is important to close the file after writing to ensure that all data is properly saved and that system resources are released.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-228e10554f05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image as im\n",
    " \n",
    "video_capture = cv2.VideoCapture(0)\n",
    " \n",
    "jobs_image = face_recognition.load_image_file(\"face_recognisation/photos/jobs.jpg\")\n",
    "jobs_encoding = face_recognition.face_encodings(jobs_image)[0]\n",
    " \n",
    "ratan_tata_image = face_recognition.load_image_file(\"face_recognisation/photos/tata.jpg\")\n",
    "ratan_tata_encoding = face_recognition.face_encodings(ratan_tata_image)[0]\n",
    " \n",
    "kohli_image = face_recognition.load_image_file(\"face_recognisation/photos/kohli.jpg\")\n",
    "kohli_encoding = face_recognition.face_encodings(kohli_image)[0]\n",
    "\n",
    "tesla_image = face_recognition.load_image_file(\"face_recognisation/photos/tesla.jpg\")\n",
    "tesla_encoding = face_recognition.face_encodings(tesla_image)[0]\n",
    "\n",
    "known_face_encoding = [\n",
    "jobs_encoding,\n",
    "ratan_tata_encoding,\n",
    "kohli_encoding,\n",
    "tesla_encoding\n",
    "]\n",
    " \n",
    "known_faces_names = [\n",
    "\"jobs\",\n",
    "\"ratan tata\",\n",
    "\"sadmona\",\n",
    "\"tesla\"\n",
    "]\n",
    " \n",
    "students = known_faces_names.copy()\n",
    " \n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "s=True\n",
    " \n",
    " \n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    " \n",
    " \n",
    "f = open(current_date+'.csv','w+',newline = '')\n",
    "lnwriter = csv.writer(f)\n",
    " \n",
    "while True:\n",
    "    _,frame = video_capture.read()\n",
    "    # im.fromarray(frame).show()\n",
    "    small_frame = cv2.resize(frame,(0,0),fx=0.25,fy=0.25)\n",
    "    # im.fromarray(small_frame).show()\n",
    "    rgb_small_frame = small_frame[:,:,::-1]\n",
    "    # im.fromarray(rgb_small_frame).show()\n",
    "    if s:\n",
    "        face_location1 = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encoding1 = face_recognition.face_encodings(rgb_small_frame.astype('uint8'),face_location1)\n",
    "        face_names = []\n",
    "        for face_encoding, face_location in zip(face_encoding1,face_location1):\n",
    "            matches = face_recognition.compare_faces(known_face_encoding,face_encoding)\n",
    "            # print(matches)\n",
    "            name=\"\"\n",
    "            face_distance = face_recognition.face_distance(known_face_encoding,face_encoding)\n",
    "            best_match_index = np.argmin(face_distance)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_faces_names[best_match_index]\n",
    " \n",
    "            face_names.append(name)\n",
    "            if name in known_faces_names:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                bottomLeftCornerOfText = (10,100)\n",
    "                fontScale              = 1.5\n",
    "                fontColor              = (255,0,0)\n",
    "                thickness              = 3\n",
    "                lineType               = 2\n",
    " \n",
    "                cv2.putText(frame,name+' Present', \n",
    "                    bottomLeftCornerOfText, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    thickness,\n",
    "                    lineType)\n",
    " \n",
    "                if name in students:\n",
    "                    students.remove(name)\n",
    "                    print(students)\n",
    "                    current_time = now.strftime(\"%H-%M-%S\")\n",
    "                    lnwriter.writerow([name,current_time])\n",
    "    cv2.imshow(\"Attendence System\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
